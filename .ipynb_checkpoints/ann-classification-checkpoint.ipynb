{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO</th>\n",
       "      <th>NAMA RUMAH</th>\n",
       "      <th>HARGA</th>\n",
       "      <th>LB</th>\n",
       "      <th>LT</th>\n",
       "      <th>KT</th>\n",
       "      <th>KM</th>\n",
       "      <th>GRS</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rumah Murah Hook Tebet Timur, Tebet, Jakarta S...</td>\n",
       "      <td>3800000000</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rumah Modern di Tebet dekat Stasiun, Tebet, Ja...</td>\n",
       "      <td>4600000000</td>\n",
       "      <td>180</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rumah Mewah 2 Lantai Hanya 3 Menit Ke Tebet, T...</td>\n",
       "      <td>3000000000</td>\n",
       "      <td>267</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rumah Baru Tebet, Tebet, Jakarta Selatan</td>\n",
       "      <td>430000000</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rumah Bagus Tebet komp Gudang Peluru lt 350m, ...</td>\n",
       "      <td>9000000000</td>\n",
       "      <td>400</td>\n",
       "      <td>355</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO                                         NAMA RUMAH       HARGA   LB  \\\n",
       "0   1  Rumah Murah Hook Tebet Timur, Tebet, Jakarta S...  3800000000  220   \n",
       "1   2  Rumah Modern di Tebet dekat Stasiun, Tebet, Ja...  4600000000  180   \n",
       "2   3  Rumah Mewah 2 Lantai Hanya 3 Menit Ke Tebet, T...  3000000000  267   \n",
       "3   4           Rumah Baru Tebet, Tebet, Jakarta Selatan   430000000   40   \n",
       "4   5  Rumah Bagus Tebet komp Gudang Peluru lt 350m, ...  9000000000  400   \n",
       "\n",
       "    LT  KT  KM  GRS  class  \n",
       "0  220   3   3    0      2  \n",
       "1  137   4   3    2      2  \n",
       "2  250   4   4    4      1  \n",
       "3   25   2   2    0      1  \n",
       "4  355   6   5    3      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "df = pd.read_excel('data/data-rumah-class-test.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    339\n",
       "1    338\n",
       "0    333\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check count of each class\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    2\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: class, dtype: int64\n",
      "    LB   LT  KT  KM  GRS\n",
      "0  220  220   3   3    0\n",
      "1  180  137   4   3    2\n",
      "2  267  250   4   4    4\n",
      "3   40   25   2   2    0\n",
      "4  400  355   6   5    3\n"
     ]
    }
   ],
   "source": [
    "#define predictor and target for classification\n",
    "\n",
    "target = 'class'\n",
    "predictor = ['LB','LT','KT','KM','GRS']\n",
    "X = df[target]\n",
    "y = df[predictor]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808,)\n",
      "(808, 5)\n",
      "(202,)\n",
      "(202, 5)\n"
     ]
    }
   ],
   "source": [
    "#split data to training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=200)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 3)\n",
      "(202, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_categorical = to_categorical(X_train)\n",
    "X_test_categorical = to_categorical(X_test)\n",
    "\n",
    "print(X_train_categorical.shape)\n",
    "print(X_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=5, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile kelas model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "808/808 [==============================] - 0s 380us/step - loss: 5.5739 - accuracy: 0.5722\n",
      "Epoch 2/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.6714 - accuracy: 0.6848\n",
      "Epoch 3/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.6094 - accuracy: 0.6840\n",
      "Epoch 4/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.5999 - accuracy: 0.6902\n",
      "Epoch 5/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.5962 - accuracy: 0.6951\n",
      "Epoch 6/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.5898 - accuracy: 0.6960\n",
      "Epoch 7/150\n",
      "808/808 [==============================] - 0s 69us/step - loss: 0.5666 - accuracy: 0.7129\n",
      "Epoch 8/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.5575 - accuracy: 0.7141\n",
      "Epoch 9/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.5507 - accuracy: 0.7108\n",
      "Epoch 10/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.5293 - accuracy: 0.7228\n",
      "Epoch 11/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.5097 - accuracy: 0.7281\n",
      "Epoch 12/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.5096 - accuracy: 0.7265\n",
      "Epoch 13/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.4931 - accuracy: 0.7327\n",
      "Epoch 14/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.4986 - accuracy: 0.7285\n",
      "Epoch 15/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.4737 - accuracy: 0.7331\n",
      "Epoch 16/150\n",
      "808/808 [==============================] - 0s 105us/step - loss: 0.4799 - accuracy: 0.7351\n",
      "Epoch 17/150\n",
      "808/808 [==============================] - 0s 93us/step - loss: 0.4658 - accuracy: 0.7459\n",
      "Epoch 18/150\n",
      "808/808 [==============================] - 0s 106us/step - loss: 0.4584 - accuracy: 0.7677\n",
      "Epoch 19/150\n",
      "808/808 [==============================] - 0s 104us/step - loss: 0.4451 - accuracy: 0.7624\n",
      "Epoch 20/150\n",
      "808/808 [==============================] - 0s 94us/step - loss: 0.4434 - accuracy: 0.7620\n",
      "Epoch 21/150\n",
      "808/808 [==============================] - 0s 91us/step - loss: 0.4399 - accuracy: 0.7653\n",
      "Epoch 22/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.4558 - accuracy: 0.7558\n",
      "Epoch 23/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.4323 - accuracy: 0.7851\n",
      "Epoch 24/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.4322 - accuracy: 0.7863\n",
      "Epoch 25/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.4292 - accuracy: 0.7884\n",
      "Epoch 26/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.4180 - accuracy: 0.7987\n",
      "Epoch 27/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.4341 - accuracy: 0.7896\n",
      "Epoch 28/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.4123 - accuracy: 0.8061\n",
      "Epoch 29/150\n",
      "808/808 [==============================] - 0s 73us/step - loss: 0.4623 - accuracy: 0.7842\n",
      "Epoch 30/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.4358 - accuracy: 0.7925\n",
      "Epoch 31/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4593 - accuracy: 0.7785\n",
      "Epoch 32/150\n",
      "808/808 [==============================] - 0s 89us/step - loss: 0.4225 - accuracy: 0.7970\n",
      "Epoch 33/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.4211 - accuracy: 0.8057\n",
      "Epoch 34/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4107 - accuracy: 0.8065\n",
      "Epoch 35/150\n",
      "808/808 [==============================] - 0s 93us/step - loss: 0.4019 - accuracy: 0.8106\n",
      "Epoch 36/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.4089 - accuracy: 0.8106\n",
      "Epoch 37/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.3953 - accuracy: 0.8205\n",
      "Epoch 38/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.4005 - accuracy: 0.8189\n",
      "Epoch 39/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4004 - accuracy: 0.8139\n",
      "Epoch 40/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3967 - accuracy: 0.8168\n",
      "Epoch 41/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3899 - accuracy: 0.8238\n",
      "Epoch 42/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3935 - accuracy: 0.8238\n",
      "Epoch 43/150\n",
      "808/808 [==============================] - 0s 90us/step - loss: 0.3955 - accuracy: 0.8226\n",
      "Epoch 44/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.4094 - accuracy: 0.8115\n",
      "Epoch 45/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3919 - accuracy: 0.8226\n",
      "Epoch 46/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3893 - accuracy: 0.8288\n",
      "Epoch 47/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3881 - accuracy: 0.8288\n",
      "Epoch 48/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3848 - accuracy: 0.8366\n",
      "Epoch 49/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.3870 - accuracy: 0.8197\n",
      "Epoch 50/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4107 - accuracy: 0.8045\n",
      "Epoch 51/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.4043 - accuracy: 0.8148\n",
      "Epoch 52/150\n",
      "808/808 [==============================] - 0s 93us/step - loss: 0.3875 - accuracy: 0.8177\n",
      "Epoch 53/150\n",
      "808/808 [==============================] - 0s 97us/step - loss: 0.3900 - accuracy: 0.8172\n",
      "Epoch 54/150\n",
      "808/808 [==============================] - 0s 106us/step - loss: 0.3833 - accuracy: 0.8201\n",
      "Epoch 55/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3881 - accuracy: 0.8106\n",
      "Epoch 56/150\n",
      "808/808 [==============================] - 0s 85us/step - loss: 0.3792 - accuracy: 0.8271\n",
      "Epoch 57/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3768 - accuracy: 0.8370\n",
      "Epoch 58/150\n",
      "808/808 [==============================] - 0s 70us/step - loss: 0.3964 - accuracy: 0.8069\n",
      "Epoch 59/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3887 - accuracy: 0.8251\n",
      "Epoch 60/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3777 - accuracy: 0.8243\n",
      "Epoch 61/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3972 - accuracy: 0.8115\n",
      "Epoch 62/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.4063 - accuracy: 0.7995\n",
      "Epoch 63/150\n",
      "808/808 [==============================] - 0s 88us/step - loss: 0.4040 - accuracy: 0.8057\n",
      "Epoch 64/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3700 - accuracy: 0.8300\n",
      "Epoch 65/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.4000 - accuracy: 0.8065\n",
      "Epoch 66/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3735 - accuracy: 0.8329\n",
      "Epoch 67/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.3841 - accuracy: 0.8234\n",
      "Epoch 68/150\n",
      "808/808 [==============================] - 0s 89us/step - loss: 0.3822 - accuracy: 0.8375\n",
      "Epoch 69/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3868 - accuracy: 0.8280\n",
      "Epoch 70/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3847 - accuracy: 0.8119\n",
      "Epoch 71/150\n",
      "808/808 [==============================] - 0s 101us/step - loss: 0.3665 - accuracy: 0.8362\n",
      "Epoch 72/150\n",
      "808/808 [==============================] - 0s 89us/step - loss: 0.3748 - accuracy: 0.8267\n",
      "Epoch 73/150\n",
      "808/808 [==============================] - 0s 88us/step - loss: 0.3806 - accuracy: 0.8300\n",
      "Epoch 74/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3850 - accuracy: 0.8259\n",
      "Epoch 75/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.4047 - accuracy: 0.8123\n",
      "Epoch 76/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3705 - accuracy: 0.8358\n",
      "Epoch 77/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.3618 - accuracy: 0.8395\n",
      "Epoch 78/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3597 - accuracy: 0.8362\n",
      "Epoch 79/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3808 - accuracy: 0.8214\n",
      "Epoch 80/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3624 - accuracy: 0.8383\n",
      "Epoch 81/150\n",
      "808/808 [==============================] - 0s 94us/step - loss: 0.3731 - accuracy: 0.8214\n",
      "Epoch 82/150\n",
      "808/808 [==============================] - 0s 97us/step - loss: 0.3628 - accuracy: 0.8403\n",
      "Epoch 83/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3618 - accuracy: 0.8350\n",
      "Epoch 84/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.3694 - accuracy: 0.8226\n",
      "Epoch 85/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3564 - accuracy: 0.8449\n",
      "Epoch 86/150\n",
      "808/808 [==============================] - 0s 73us/step - loss: 0.3620 - accuracy: 0.8333\n",
      "Epoch 87/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3590 - accuracy: 0.8379\n",
      "Epoch 88/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3590 - accuracy: 0.8412\n",
      "Epoch 89/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.3547 - accuracy: 0.8403\n",
      "Epoch 90/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3512 - accuracy: 0.8469\n",
      "Epoch 91/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3500 - accuracy: 0.8408\n",
      "Epoch 92/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3630 - accuracy: 0.8337\n",
      "Epoch 93/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.3560 - accuracy: 0.8346\n",
      "Epoch 94/150\n",
      "808/808 [==============================] - 0s 102us/step - loss: 0.3503 - accuracy: 0.8445\n",
      "Epoch 95/150\n",
      "808/808 [==============================] - 0s 108us/step - loss: 0.3653 - accuracy: 0.8362\n",
      "Epoch 96/150\n",
      "808/808 [==============================] - 0s 100us/step - loss: 0.3690 - accuracy: 0.8354\n",
      "Epoch 97/150\n",
      "808/808 [==============================] - 0s 100us/step - loss: 0.3573 - accuracy: 0.8346\n",
      "Epoch 98/150\n",
      "808/808 [==============================] - 0s 102us/step - loss: 0.3484 - accuracy: 0.8420\n",
      "Epoch 99/150\n",
      "808/808 [==============================] - 0s 115us/step - loss: 0.3583 - accuracy: 0.8416\n",
      "Epoch 100/150\n",
      "808/808 [==============================] - 0s 97us/step - loss: 0.3585 - accuracy: 0.8432\n",
      "Epoch 101/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3474 - accuracy: 0.8449\n",
      "Epoch 102/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3450 - accuracy: 0.8424\n",
      "Epoch 103/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3517 - accuracy: 0.8424\n",
      "Epoch 104/150\n",
      "808/808 [==============================] - 0s 66us/step - loss: 0.3667 - accuracy: 0.8358\n",
      "Epoch 105/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3619 - accuracy: 0.8333\n",
      "Epoch 106/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3491 - accuracy: 0.8379\n",
      "Epoch 107/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3491 - accuracy: 0.8391\n",
      "Epoch 108/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.3505 - accuracy: 0.8424\n",
      "Epoch 109/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.3460 - accuracy: 0.8486\n",
      "Epoch 110/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3402 - accuracy: 0.8461\n",
      "Epoch 111/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3579 - accuracy: 0.8362\n",
      "Epoch 112/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3527 - accuracy: 0.8329\n",
      "Epoch 113/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3471 - accuracy: 0.8424\n",
      "Epoch 114/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.3493 - accuracy: 0.8395\n",
      "Epoch 115/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3423 - accuracy: 0.8445\n",
      "Epoch 116/150\n",
      "808/808 [==============================] - 0s 66us/step - loss: 0.3552 - accuracy: 0.8399\n",
      "Epoch 117/150\n",
      "808/808 [==============================] - 0s 70us/step - loss: 0.3405 - accuracy: 0.8424\n",
      "Epoch 118/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3453 - accuracy: 0.8461\n",
      "Epoch 119/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3352 - accuracy: 0.8519\n",
      "Epoch 120/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3436 - accuracy: 0.8395\n",
      "Epoch 121/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3372 - accuracy: 0.8511\n",
      "Epoch 122/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.3351 - accuracy: 0.8412\n",
      "Epoch 123/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3379 - accuracy: 0.8465\n",
      "Epoch 124/150\n",
      "808/808 [==============================] - 0s 70us/step - loss: 0.3371 - accuracy: 0.8523\n",
      "Epoch 125/150\n",
      "808/808 [==============================] - 0s 68us/step - loss: 0.3405 - accuracy: 0.8511\n",
      "Epoch 126/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3371 - accuracy: 0.8515\n",
      "Epoch 127/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.3393 - accuracy: 0.8498\n",
      "Epoch 128/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3506 - accuracy: 0.8432\n",
      "Epoch 129/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3355 - accuracy: 0.8465\n",
      "Epoch 130/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3308 - accuracy: 0.8540\n",
      "Epoch 131/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3600 - accuracy: 0.8416\n",
      "Epoch 132/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3376 - accuracy: 0.8540\n",
      "Epoch 133/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3305 - accuracy: 0.8515\n",
      "Epoch 134/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3312 - accuracy: 0.8453\n",
      "Epoch 135/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3426 - accuracy: 0.8482\n",
      "Epoch 136/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3534 - accuracy: 0.8259\n",
      "Epoch 137/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3422 - accuracy: 0.8387\n",
      "Epoch 138/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3367 - accuracy: 0.8507\n",
      "Epoch 139/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3317 - accuracy: 0.8544\n",
      "Epoch 140/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3326 - accuracy: 0.8535\n",
      "Epoch 141/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3509 - accuracy: 0.8304\n",
      "Epoch 142/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3400 - accuracy: 0.8445\n",
      "Epoch 143/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3387 - accuracy: 0.8449\n",
      "Epoch 144/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3273 - accuracy: 0.8527\n",
      "Epoch 145/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.3442 - accuracy: 0.8395\n",
      "Epoch 146/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3629 - accuracy: 0.8309\n",
      "Epoch 147/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3339 - accuracy: 0.8465\n",
      "Epoch 148/150\n",
      "808/808 [==============================] - 0s 61us/step - loss: 0.3319 - accuracy: 0.8502\n",
      "Epoch 149/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3295 - accuracy: 0.8552\n",
      "Epoch 150/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3282 - accuracy: 0.8544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17ff386eb00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "\n",
    "model.fit(y_train, X_train_categorical, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s 78us/step\n",
      "Accuracy on training data: 0.844059407711029% \n",
      " Error on training data: 0.15594059228897095\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "\n",
    "scores = model.evaluate(y_train, X_train_categorical)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 1, 2, 0, 1, 1,\n",
       "       2, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 2, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 1, 1,\n",
       "       0, 1, 2, 1, 1, 0, 2, 1, 0, 2, 0, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 0, 2, 2, 0, 2, 2,\n",
       "       2, 1, 0, 2, 1, 1, 1, 2, 1, 2, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 2, 0, 2, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 0, 2, 2, 1,\n",
       "       1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTesting = y_test\n",
    "predictions = model.predict_classes(dataTesting)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>LT</th>\n",
       "      <th>KT</th>\n",
       "      <th>KM</th>\n",
       "      <th>GRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>154</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>210</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>120</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>480</td>\n",
       "      <td>312</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>210</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>270</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>150</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>200</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>150</td>\n",
       "      <td>135</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>170</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>800</td>\n",
       "      <td>498</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>150</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>444</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>200</td>\n",
       "      <td>385</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>150</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>275</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>200</td>\n",
       "      <td>393</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>800</td>\n",
       "      <td>361</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>135</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>325</td>\n",
       "      <td>226</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>170</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>350</td>\n",
       "      <td>448</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>340</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>235</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>300</td>\n",
       "      <td>248</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>215</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>250</td>\n",
       "      <td>162</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>450</td>\n",
       "      <td>700</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>480</td>\n",
       "      <td>378</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>1000</td>\n",
       "      <td>670</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>350</td>\n",
       "      <td>565</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>200</td>\n",
       "      <td>220</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>700</td>\n",
       "      <td>547</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>350</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>400</td>\n",
       "      <td>932</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>180</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>150</td>\n",
       "      <td>253</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>220</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>800</td>\n",
       "      <td>498</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>180</td>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>170</td>\n",
       "      <td>141</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>175</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>150</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>500</td>\n",
       "      <td>345</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>225</td>\n",
       "      <td>156</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>440</td>\n",
       "      <td>393</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LB   LT  KT  KM  GRS\n",
       "958   200  130   4   3    2\n",
       "283   300  200   5   7    4\n",
       "356   154  204   5   2    0\n",
       "278   210   91   5   3    0\n",
       "295   120  152   4   4    4\n",
       "313   200  256   5   3    3\n",
       "419   480  312   4   2    1\n",
       "970   210   91   5   4    1\n",
       "259   200  150   4   4    2\n",
       "500   270  140   3   3    4\n",
       "41    150   90   3   2    2\n",
       "801   150  135   5   3    3\n",
       "235   200  130   3   3    2\n",
       "725   150  135   3   1    1\n",
       "982   160  110   3   3    1\n",
       "256   170  154   5   3    2\n",
       "715   800  498   5   5    9\n",
       "225   150  159   5   4    2\n",
       "260   444  200  10  10    2\n",
       "799   200  385   5   5    0\n",
       "953   120   60   3   4    1\n",
       "705   150  102   3   3    1\n",
       "499   275  150   4   5    1\n",
       "58    200  393   5   3    1\n",
       "610   140   90   3   2    2\n",
       "530   800  361   5   4    4\n",
       "410   135   87   3   2    2\n",
       "541   325  226   6   5    1\n",
       "181   170   76   3   3    2\n",
       "804   350  448   6   7    4\n",
       "..    ...  ...  ..  ..  ...\n",
       "123   340  240   4   3    2\n",
       "455   235  140   5   4    2\n",
       "876   300  248   5   4    3\n",
       "383   215  135   9   8    0\n",
       "88    150  130   5   2    1\n",
       "473   150  200   3   2    2\n",
       "621   250  162   4   3    2\n",
       "600   450  700   8   5    2\n",
       "497    80   90   2   2    1\n",
       "269   480  378   5   4    1\n",
       "645    63  300   3   1    1\n",
       "694  1000  670   5   5    5\n",
       "324   350  565   5   3    4\n",
       "976   200  220   7   3    1\n",
       "605   700  547   6   5    6\n",
       "453   350  100   4   4    2\n",
       "904   400  932   7   5    9\n",
       "546   180  127   4   4    2\n",
       "854   150  253   5   2    0\n",
       "347   150   90   3   2    1\n",
       "620   220  115   4   3    0\n",
       "839   800  498   6   6    9\n",
       "161   180  127   5   4    2\n",
       "959   170  141   4   3    1\n",
       "495   175   89   3   3    2\n",
       "940   150  112   3   4    1\n",
       "880   500  345   6   4    2\n",
       "721   225  156   4   3    2\n",
       "997   120  100   3   2    1\n",
       "963   440  393   6   6    6\n",
       "\n",
       "[202 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluation confussion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "matrix = confusion_matrix(X_test, predictions)\n",
    "sn.heatmap(matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuration score from confussion matrix using library\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(X_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7821782178217822"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check accuration score from confussion matrix using mathematics\n",
    "\n",
    "accuration = (matrix[0,0]+matrix[1,1]+matrix[2,2])/len(predictions)\n",
    "accuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
