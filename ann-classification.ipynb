{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO</th>\n",
       "      <th>NAMA RUMAH</th>\n",
       "      <th>HARGA</th>\n",
       "      <th>LB</th>\n",
       "      <th>LT</th>\n",
       "      <th>KT</th>\n",
       "      <th>KM</th>\n",
       "      <th>GRS</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rumah Murah Hook Tebet Timur, Tebet, Jakarta S...</td>\n",
       "      <td>3800000000</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rumah Modern di Tebet dekat Stasiun, Tebet, Ja...</td>\n",
       "      <td>4600000000</td>\n",
       "      <td>180</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rumah Mewah 2 Lantai Hanya 3 Menit Ke Tebet, T...</td>\n",
       "      <td>3000000000</td>\n",
       "      <td>267</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rumah Baru Tebet, Tebet, Jakarta Selatan</td>\n",
       "      <td>430000000</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rumah Bagus Tebet komp Gudang Peluru lt 350m, ...</td>\n",
       "      <td>9000000000</td>\n",
       "      <td>400</td>\n",
       "      <td>355</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO                                         NAMA RUMAH       HARGA   LB  \\\n",
       "0   1  Rumah Murah Hook Tebet Timur, Tebet, Jakarta S...  3800000000  220   \n",
       "1   2  Rumah Modern di Tebet dekat Stasiun, Tebet, Ja...  4600000000  180   \n",
       "2   3  Rumah Mewah 2 Lantai Hanya 3 Menit Ke Tebet, T...  3000000000  267   \n",
       "3   4           Rumah Baru Tebet, Tebet, Jakarta Selatan   430000000   40   \n",
       "4   5  Rumah Bagus Tebet komp Gudang Peluru lt 350m, ...  9000000000  400   \n",
       "\n",
       "    LT  KT  KM  GRS  class  \n",
       "0  220   3   3    0      2  \n",
       "1  137   4   3    2      2  \n",
       "2  250   4   4    4      1  \n",
       "3   25   2   2    0      1  \n",
       "4  355   6   5    3      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "df = pd.read_excel('data/data-rumah-class-test.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    339\n",
       "1    338\n",
       "0    333\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check count of each class\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    2\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: class, dtype: int64\n",
      "    LB   LT  KT  KM  GRS\n",
      "0  220  220   3   3    0\n",
      "1  180  137   4   3    2\n",
      "2  267  250   4   4    4\n",
      "3   40   25   2   2    0\n",
      "4  400  355   6   5    3\n"
     ]
    }
   ],
   "source": [
    "#define predictor and target for classification\n",
    "\n",
    "target = 'class'\n",
    "predictor = ['LB','LT','KT','KM','GRS']\n",
    "X = df[target]\n",
    "y = df[predictor]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808,)\n",
      "(808, 5)\n",
      "(202,)\n",
      "(202, 5)\n"
     ]
    }
   ],
   "source": [
    "#split data to training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=200)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 3)\n",
      "(202, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_categorical = to_categorical(X_train)\n",
    "X_test_categorical = to_categorical(X_test)\n",
    "\n",
    "print(X_train_categorical.shape)\n",
    "print(X_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=5, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile kelas model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "808/808 [==============================] - 0s 380us/step - loss: 5.5739 - accuracy: 0.5722\n",
      "Epoch 2/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.6714 - accuracy: 0.6848\n",
      "Epoch 3/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.6094 - accuracy: 0.6840\n",
      "Epoch 4/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.5999 - accuracy: 0.6902\n",
      "Epoch 5/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.5962 - accuracy: 0.6951\n",
      "Epoch 6/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.5898 - accuracy: 0.6960\n",
      "Epoch 7/150\n",
      "808/808 [==============================] - 0s 69us/step - loss: 0.5666 - accuracy: 0.7129\n",
      "Epoch 8/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.5575 - accuracy: 0.7141\n",
      "Epoch 9/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.5507 - accuracy: 0.7108\n",
      "Epoch 10/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.5293 - accuracy: 0.7228\n",
      "Epoch 11/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.5097 - accuracy: 0.7281\n",
      "Epoch 12/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.5096 - accuracy: 0.7265\n",
      "Epoch 13/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.4931 - accuracy: 0.7327\n",
      "Epoch 14/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.4986 - accuracy: 0.7285\n",
      "Epoch 15/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.4737 - accuracy: 0.7331\n",
      "Epoch 16/150\n",
      "808/808 [==============================] - 0s 105us/step - loss: 0.4799 - accuracy: 0.7351\n",
      "Epoch 17/150\n",
      "808/808 [==============================] - 0s 93us/step - loss: 0.4658 - accuracy: 0.7459\n",
      "Epoch 18/150\n",
      "808/808 [==============================] - 0s 106us/step - loss: 0.4584 - accuracy: 0.7677\n",
      "Epoch 19/150\n",
      "808/808 [==============================] - 0s 104us/step - loss: 0.4451 - accuracy: 0.7624\n",
      "Epoch 20/150\n",
      "808/808 [==============================] - 0s 94us/step - loss: 0.4434 - accuracy: 0.7620\n",
      "Epoch 21/150\n",
      "808/808 [==============================] - 0s 91us/step - loss: 0.4399 - accuracy: 0.7653\n",
      "Epoch 22/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.4558 - accuracy: 0.7558\n",
      "Epoch 23/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.4323 - accuracy: 0.7851\n",
      "Epoch 24/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.4322 - accuracy: 0.7863\n",
      "Epoch 25/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.4292 - accuracy: 0.7884\n",
      "Epoch 26/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.4180 - accuracy: 0.7987\n",
      "Epoch 27/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.4341 - accuracy: 0.7896\n",
      "Epoch 28/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.4123 - accuracy: 0.8061\n",
      "Epoch 29/150\n",
      "808/808 [==============================] - 0s 73us/step - loss: 0.4623 - accuracy: 0.7842\n",
      "Epoch 30/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.4358 - accuracy: 0.7925\n",
      "Epoch 31/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4593 - accuracy: 0.7785\n",
      "Epoch 32/150\n",
      "808/808 [==============================] - 0s 89us/step - loss: 0.4225 - accuracy: 0.7970\n",
      "Epoch 33/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.4211 - accuracy: 0.8057\n",
      "Epoch 34/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4107 - accuracy: 0.8065\n",
      "Epoch 35/150\n",
      "808/808 [==============================] - 0s 93us/step - loss: 0.4019 - accuracy: 0.8106\n",
      "Epoch 36/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.4089 - accuracy: 0.8106\n",
      "Epoch 37/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.3953 - accuracy: 0.8205\n",
      "Epoch 38/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.4005 - accuracy: 0.8189\n",
      "Epoch 39/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4004 - accuracy: 0.8139\n",
      "Epoch 40/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3967 - accuracy: 0.8168\n",
      "Epoch 41/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3899 - accuracy: 0.8238\n",
      "Epoch 42/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3935 - accuracy: 0.8238\n",
      "Epoch 43/150\n",
      "808/808 [==============================] - 0s 90us/step - loss: 0.3955 - accuracy: 0.8226\n",
      "Epoch 44/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.4094 - accuracy: 0.8115\n",
      "Epoch 45/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3919 - accuracy: 0.8226\n",
      "Epoch 46/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3893 - accuracy: 0.8288\n",
      "Epoch 47/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3881 - accuracy: 0.8288\n",
      "Epoch 48/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3848 - accuracy: 0.8366\n",
      "Epoch 49/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.3870 - accuracy: 0.8197\n",
      "Epoch 50/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.4107 - accuracy: 0.8045\n",
      "Epoch 51/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.4043 - accuracy: 0.8148\n",
      "Epoch 52/150\n",
      "808/808 [==============================] - 0s 93us/step - loss: 0.3875 - accuracy: 0.8177\n",
      "Epoch 53/150\n",
      "808/808 [==============================] - 0s 97us/step - loss: 0.3900 - accuracy: 0.8172\n",
      "Epoch 54/150\n",
      "808/808 [==============================] - 0s 106us/step - loss: 0.3833 - accuracy: 0.8201\n",
      "Epoch 55/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3881 - accuracy: 0.8106\n",
      "Epoch 56/150\n",
      "808/808 [==============================] - 0s 85us/step - loss: 0.3792 - accuracy: 0.8271\n",
      "Epoch 57/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3768 - accuracy: 0.8370\n",
      "Epoch 58/150\n",
      "808/808 [==============================] - 0s 70us/step - loss: 0.3964 - accuracy: 0.8069\n",
      "Epoch 59/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3887 - accuracy: 0.8251\n",
      "Epoch 60/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3777 - accuracy: 0.8243\n",
      "Epoch 61/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3972 - accuracy: 0.8115\n",
      "Epoch 62/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.4063 - accuracy: 0.7995\n",
      "Epoch 63/150\n",
      "808/808 [==============================] - 0s 88us/step - loss: 0.4040 - accuracy: 0.8057\n",
      "Epoch 64/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3700 - accuracy: 0.8300\n",
      "Epoch 65/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.4000 - accuracy: 0.8065\n",
      "Epoch 66/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3735 - accuracy: 0.8329\n",
      "Epoch 67/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.3841 - accuracy: 0.8234\n",
      "Epoch 68/150\n",
      "808/808 [==============================] - 0s 89us/step - loss: 0.3822 - accuracy: 0.8375\n",
      "Epoch 69/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3868 - accuracy: 0.8280\n",
      "Epoch 70/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3847 - accuracy: 0.8119\n",
      "Epoch 71/150\n",
      "808/808 [==============================] - 0s 101us/step - loss: 0.3665 - accuracy: 0.8362\n",
      "Epoch 72/150\n",
      "808/808 [==============================] - 0s 89us/step - loss: 0.3748 - accuracy: 0.8267\n",
      "Epoch 73/150\n",
      "808/808 [==============================] - 0s 88us/step - loss: 0.3806 - accuracy: 0.8300\n",
      "Epoch 74/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3850 - accuracy: 0.8259\n",
      "Epoch 75/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.4047 - accuracy: 0.8123\n",
      "Epoch 76/150\n",
      "808/808 [==============================] - 0s 82us/step - loss: 0.3705 - accuracy: 0.8358\n",
      "Epoch 77/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.3618 - accuracy: 0.8395\n",
      "Epoch 78/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3597 - accuracy: 0.8362\n",
      "Epoch 79/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3808 - accuracy: 0.8214\n",
      "Epoch 80/150\n",
      "808/808 [==============================] - 0s 87us/step - loss: 0.3624 - accuracy: 0.8383\n",
      "Epoch 81/150\n",
      "808/808 [==============================] - 0s 94us/step - loss: 0.3731 - accuracy: 0.8214\n",
      "Epoch 82/150\n",
      "808/808 [==============================] - 0s 97us/step - loss: 0.3628 - accuracy: 0.8403\n",
      "Epoch 83/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3618 - accuracy: 0.8350\n",
      "Epoch 84/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.3694 - accuracy: 0.8226\n",
      "Epoch 85/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3564 - accuracy: 0.8449\n",
      "Epoch 86/150\n",
      "808/808 [==============================] - 0s 73us/step - loss: 0.3620 - accuracy: 0.8333\n",
      "Epoch 87/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3590 - accuracy: 0.8379\n",
      "Epoch 88/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3590 - accuracy: 0.8412\n",
      "Epoch 89/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.3547 - accuracy: 0.8403\n",
      "Epoch 90/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3512 - accuracy: 0.8469\n",
      "Epoch 91/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3500 - accuracy: 0.8408\n",
      "Epoch 92/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3630 - accuracy: 0.8337\n",
      "Epoch 93/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.3560 - accuracy: 0.8346\n",
      "Epoch 94/150\n",
      "808/808 [==============================] - 0s 102us/step - loss: 0.3503 - accuracy: 0.8445\n",
      "Epoch 95/150\n",
      "808/808 [==============================] - 0s 108us/step - loss: 0.3653 - accuracy: 0.8362\n",
      "Epoch 96/150\n",
      "808/808 [==============================] - 0s 100us/step - loss: 0.3690 - accuracy: 0.8354\n",
      "Epoch 97/150\n",
      "808/808 [==============================] - 0s 100us/step - loss: 0.3573 - accuracy: 0.8346\n",
      "Epoch 98/150\n",
      "808/808 [==============================] - 0s 102us/step - loss: 0.3484 - accuracy: 0.8420\n",
      "Epoch 99/150\n",
      "808/808 [==============================] - 0s 115us/step - loss: 0.3583 - accuracy: 0.8416\n",
      "Epoch 100/150\n",
      "808/808 [==============================] - 0s 97us/step - loss: 0.3585 - accuracy: 0.8432\n",
      "Epoch 101/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3474 - accuracy: 0.8449\n",
      "Epoch 102/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3450 - accuracy: 0.8424\n",
      "Epoch 103/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3517 - accuracy: 0.8424\n",
      "Epoch 104/150\n",
      "808/808 [==============================] - 0s 66us/step - loss: 0.3667 - accuracy: 0.8358\n",
      "Epoch 105/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3619 - accuracy: 0.8333\n",
      "Epoch 106/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3491 - accuracy: 0.8379\n",
      "Epoch 107/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3491 - accuracy: 0.8391\n",
      "Epoch 108/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.3505 - accuracy: 0.8424\n",
      "Epoch 109/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.3460 - accuracy: 0.8486\n",
      "Epoch 110/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3402 - accuracy: 0.8461\n",
      "Epoch 111/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3579 - accuracy: 0.8362\n",
      "Epoch 112/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3527 - accuracy: 0.8329\n",
      "Epoch 113/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3471 - accuracy: 0.8424\n",
      "Epoch 114/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.3493 - accuracy: 0.8395\n",
      "Epoch 115/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3423 - accuracy: 0.8445\n",
      "Epoch 116/150\n",
      "808/808 [==============================] - 0s 66us/step - loss: 0.3552 - accuracy: 0.8399\n",
      "Epoch 117/150\n",
      "808/808 [==============================] - 0s 70us/step - loss: 0.3405 - accuracy: 0.8424\n",
      "Epoch 118/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3453 - accuracy: 0.8461\n",
      "Epoch 119/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3352 - accuracy: 0.8519\n",
      "Epoch 120/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3436 - accuracy: 0.8395\n",
      "Epoch 121/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3372 - accuracy: 0.8511\n",
      "Epoch 122/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.3351 - accuracy: 0.8412\n",
      "Epoch 123/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3379 - accuracy: 0.8465\n",
      "Epoch 124/150\n",
      "808/808 [==============================] - 0s 70us/step - loss: 0.3371 - accuracy: 0.8523\n",
      "Epoch 125/150\n",
      "808/808 [==============================] - 0s 68us/step - loss: 0.3405 - accuracy: 0.8511\n",
      "Epoch 126/150\n",
      "808/808 [==============================] - 0s 76us/step - loss: 0.3371 - accuracy: 0.8515\n",
      "Epoch 127/150\n",
      "808/808 [==============================] - 0s 74us/step - loss: 0.3393 - accuracy: 0.8498\n",
      "Epoch 128/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3506 - accuracy: 0.8432\n",
      "Epoch 129/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3355 - accuracy: 0.8465\n",
      "Epoch 130/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3308 - accuracy: 0.8540\n",
      "Epoch 131/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3600 - accuracy: 0.8416\n",
      "Epoch 132/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3376 - accuracy: 0.8540\n",
      "Epoch 133/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3305 - accuracy: 0.8515\n",
      "Epoch 134/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3312 - accuracy: 0.8453\n",
      "Epoch 135/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3426 - accuracy: 0.8482\n",
      "Epoch 136/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3534 - accuracy: 0.8259\n",
      "Epoch 137/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3422 - accuracy: 0.8387\n",
      "Epoch 138/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3367 - accuracy: 0.8507\n",
      "Epoch 139/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3317 - accuracy: 0.8544\n",
      "Epoch 140/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3326 - accuracy: 0.8535\n",
      "Epoch 141/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3509 - accuracy: 0.8304\n",
      "Epoch 142/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3400 - accuracy: 0.8445\n",
      "Epoch 143/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3387 - accuracy: 0.8449\n",
      "Epoch 144/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3273 - accuracy: 0.8527\n",
      "Epoch 145/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.3442 - accuracy: 0.8395\n",
      "Epoch 146/150\n",
      "808/808 [==============================] - 0s 71us/step - loss: 0.3629 - accuracy: 0.8309\n",
      "Epoch 147/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3339 - accuracy: 0.8465\n",
      "Epoch 148/150\n",
      "808/808 [==============================] - 0s 61us/step - loss: 0.3319 - accuracy: 0.8502\n",
      "Epoch 149/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3295 - accuracy: 0.8552\n",
      "Epoch 150/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3282 - accuracy: 0.8544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17ff386eb00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "\n",
    "model.fit(y_train, X_train_categorical, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s 78us/step\n",
      "Accuracy on training data: 0.844059407711029% \n",
      " Error on training data: 0.15594059228897095\n"
     ]
    }
   ],
   "source": [
    "#evaluate train data\n",
    "\n",
    "scores = model.evaluate(y_train, X_train_categorical)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 1, 2, 0, 1, 1,\n",
       "       2, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 2, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 1, 1,\n",
       "       0, 1, 2, 1, 1, 0, 2, 1, 0, 2, 0, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 0, 2, 2, 0, 2, 2,\n",
       "       2, 1, 0, 2, 1, 1, 1, 2, 1, 2, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 2, 0, 2, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 0, 2, 2, 1,\n",
       "       1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTesting = y_test\n",
    "predictions = model.predict_classes(dataTesting)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluation confussion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matrix = confusion_matrix(X_test, predictions)\n",
    "sn.heatmap(matrix, annot=True)\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"True\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Error Rate: 0.22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuration score from confussion matrix using library\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(X_test, predictions)))\n",
    "print('Error Rate: {:.2f}\\n'.format(1 - accuracy_score(X_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7821782178217822\n",
      "Error Rate: 0.2178217821782178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuration score from confussion matrix using mathematics\n",
    "\n",
    "accuration = (matrix[0,0]+matrix[1,1]+matrix[2,2])/len(predictions)\n",
    "print('Accuracy: {}'.format(accuration))\n",
    "print('Error Rate: {}\\n'.format(1 - accuration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
