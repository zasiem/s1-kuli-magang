{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO</th>\n",
       "      <th>NAMA RUMAH</th>\n",
       "      <th>HARGA</th>\n",
       "      <th>LB</th>\n",
       "      <th>LT</th>\n",
       "      <th>KT</th>\n",
       "      <th>KM</th>\n",
       "      <th>GRS</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rumah Murah Hook Tebet Timur, Tebet, Jakarta S...</td>\n",
       "      <td>3800000000</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rumah Modern di Tebet dekat Stasiun, Tebet, Ja...</td>\n",
       "      <td>4600000000</td>\n",
       "      <td>180</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rumah Mewah 2 Lantai Hanya 3 Menit Ke Tebet, T...</td>\n",
       "      <td>3000000000</td>\n",
       "      <td>267</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rumah Baru Tebet, Tebet, Jakarta Selatan</td>\n",
       "      <td>430000000</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rumah Bagus Tebet komp Gudang Peluru lt 350m, ...</td>\n",
       "      <td>9000000000</td>\n",
       "      <td>400</td>\n",
       "      <td>355</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO                                         NAMA RUMAH       HARGA   LB  \\\n",
       "0   1  Rumah Murah Hook Tebet Timur, Tebet, Jakarta S...  3800000000  220   \n",
       "1   2  Rumah Modern di Tebet dekat Stasiun, Tebet, Ja...  4600000000  180   \n",
       "2   3  Rumah Mewah 2 Lantai Hanya 3 Menit Ke Tebet, T...  3000000000  267   \n",
       "3   4           Rumah Baru Tebet, Tebet, Jakarta Selatan   430000000   40   \n",
       "4   5  Rumah Bagus Tebet komp Gudang Peluru lt 350m, ...  9000000000  400   \n",
       "\n",
       "    LT  KT  KM  GRS  class  \n",
       "0  220   3   3    0      2  \n",
       "1  137   4   3    2      2  \n",
       "2  250   4   4    4      1  \n",
       "3   25   2   2    0      1  \n",
       "4  355   6   5    3      0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "df = pd.read_excel('data/data-rumah-class-test.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    339\n",
       "1    338\n",
       "0    333\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check count of each class\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    2\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: class, dtype: int64\n",
      "    LB   LT  KT  KM  GRS\n",
      "0  220  220   3   3    0\n",
      "1  180  137   4   3    2\n",
      "2  267  250   4   4    4\n",
      "3   40   25   2   2    0\n",
      "4  400  355   6   5    3\n"
     ]
    }
   ],
   "source": [
    "#define predictor and target for classification\n",
    "\n",
    "target = 'class'\n",
    "predictor = ['LB','LT','KT','KM','GRS']\n",
    "X = df[target]\n",
    "y = df[predictor]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808,)\n",
      "(808, 5)\n",
      "(202,)\n",
      "(202, 5)\n"
     ]
    }
   ],
   "source": [
    "#split data to training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=200)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 3)\n",
      "(202, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_categorical = to_categorical(X_train)\n",
    "X_test_categorical = to_categorical(X_test)\n",
    "\n",
    "print(X_train_categorical.shape)\n",
    "print(X_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=5, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile kelas model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "808/808 [==============================] - 0s 207us/step - loss: 6.1425 - accuracy: 0.5578\n",
      "Epoch 2/150\n",
      "808/808 [==============================] - 0s 94us/step - loss: 1.2990 - accuracy: 0.6093\n",
      "Epoch 3/150\n",
      "808/808 [==============================] - 0s 70us/step - loss: 0.6800 - accuracy: 0.6345\n",
      "Epoch 4/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.5719 - accuracy: 0.7306\n",
      "Epoch 5/150\n",
      "808/808 [==============================] - 0s 73us/step - loss: 0.5666 - accuracy: 0.7417\n",
      "Epoch 6/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.5623 - accuracy: 0.7434\n",
      "Epoch 7/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.5583 - accuracy: 0.7426\n",
      "Epoch 8/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.5534 - accuracy: 0.7438\n",
      "Epoch 9/150\n",
      "808/808 [==============================] - 0s 48us/step - loss: 0.5486 - accuracy: 0.7364\n",
      "Epoch 10/150\n",
      "808/808 [==============================] - 0s 49us/step - loss: 0.5448 - accuracy: 0.7463\n",
      "Epoch 11/150\n",
      "808/808 [==============================] - 0s 51us/step - loss: 0.5403 - accuracy: 0.7422\n",
      "Epoch 12/150\n",
      "808/808 [==============================] - 0s 51us/step - loss: 0.5360 - accuracy: 0.7368\n",
      "Epoch 13/150\n",
      "808/808 [==============================] - 0s 45us/step - loss: 0.5300 - accuracy: 0.7409\n",
      "Epoch 14/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.5249 - accuracy: 0.7335\n",
      "Epoch 15/150\n",
      "808/808 [==============================] - 0s 46us/step - loss: 0.5206 - accuracy: 0.7323\n",
      "Epoch 16/150\n",
      "808/808 [==============================] - 0s 51us/step - loss: 0.5093 - accuracy: 0.7446\n",
      "Epoch 17/150\n",
      "808/808 [==============================] - 0s 53us/step - loss: 0.5076 - accuracy: 0.7376\n",
      "Epoch 18/150\n",
      "808/808 [==============================] - 0s 60us/step - loss: 0.5172 - accuracy: 0.7389\n",
      "Epoch 19/150\n",
      "808/808 [==============================] - 0s 52us/step - loss: 0.5105 - accuracy: 0.7442\n",
      "Epoch 20/150\n",
      "808/808 [==============================] - 0s 52us/step - loss: 0.5064 - accuracy: 0.7413\n",
      "Epoch 21/150\n",
      "808/808 [==============================] - 0s 57us/step - loss: 0.4999 - accuracy: 0.7430\n",
      "Epoch 22/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.4783 - accuracy: 0.7459\n",
      "Epoch 23/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.4674 - accuracy: 0.7488\n",
      "Epoch 24/150\n",
      "808/808 [==============================] - 0s 51us/step - loss: 0.4609 - accuracy: 0.7558\n",
      "Epoch 25/150\n",
      "808/808 [==============================] - 0s 49us/step - loss: 0.4509 - accuracy: 0.7620\n",
      "Epoch 26/150\n",
      "808/808 [==============================] - 0s 40us/step - loss: 0.4558 - accuracy: 0.7512\n",
      "Epoch 27/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.4789 - accuracy: 0.7504\n",
      "Epoch 28/150\n",
      "808/808 [==============================] - 0s 47us/step - loss: 0.4465 - accuracy: 0.7686\n",
      "Epoch 29/150\n",
      "808/808 [==============================] - 0s 48us/step - loss: 0.4307 - accuracy: 0.7859\n",
      "Epoch 30/150\n",
      "808/808 [==============================] - 0s 47us/step - loss: 0.4362 - accuracy: 0.7764\n",
      "Epoch 31/150\n",
      "808/808 [==============================] - 0s 59us/step - loss: 0.4375 - accuracy: 0.7756\n",
      "Epoch 32/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.4198 - accuracy: 0.7896\n",
      "Epoch 33/150\n",
      "808/808 [==============================] - 0s 47us/step - loss: 0.4272 - accuracy: 0.7904\n",
      "Epoch 34/150\n",
      "808/808 [==============================] - 0s 53us/step - loss: 0.4257 - accuracy: 0.7950\n",
      "Epoch 35/150\n",
      "808/808 [==============================] - 0s 49us/step - loss: 0.4238 - accuracy: 0.7908\n",
      "Epoch 36/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.4391 - accuracy: 0.7764\n",
      "Epoch 37/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.4166 - accuracy: 0.7933\n",
      "Epoch 38/150\n",
      "808/808 [==============================] - 0s 48us/step - loss: 0.4127 - accuracy: 0.8016\n",
      "Epoch 39/150\n",
      "808/808 [==============================] - 0s 55us/step - loss: 0.4273 - accuracy: 0.7974\n",
      "Epoch 40/150\n",
      "808/808 [==============================] - 0s 69us/step - loss: 0.4092 - accuracy: 0.7987\n",
      "Epoch 41/150\n",
      "808/808 [==============================] - 0s 53us/step - loss: 0.4084 - accuracy: 0.8078\n",
      "Epoch 42/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.4242 - accuracy: 0.7917\n",
      "Epoch 43/150\n",
      "808/808 [==============================] - 0s 57us/step - loss: 0.4330 - accuracy: 0.7781\n",
      "Epoch 44/150\n",
      "808/808 [==============================] - 0s 85us/step - loss: 0.4035 - accuracy: 0.8040\n",
      "Epoch 45/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.3986 - accuracy: 0.8152\n",
      "Epoch 46/150\n",
      "808/808 [==============================] - 0s 56us/step - loss: 0.4136 - accuracy: 0.8003\n",
      "Epoch 47/150\n",
      "808/808 [==============================] - 0s 48us/step - loss: 0.4073 - accuracy: 0.7987\n",
      "Epoch 48/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.4027 - accuracy: 0.8028\n",
      "Epoch 49/150\n",
      "808/808 [==============================] - 0s 48us/step - loss: 0.4029 - accuracy: 0.8135\n",
      "Epoch 50/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.3916 - accuracy: 0.8263\n",
      "Epoch 51/150\n",
      "808/808 [==============================] - 0s 56us/step - loss: 0.4018 - accuracy: 0.8078\n",
      "Epoch 52/150\n",
      "808/808 [==============================] - 0s 54us/step - loss: 0.3927 - accuracy: 0.8214\n",
      "Epoch 53/150\n",
      "808/808 [==============================] - 0s 43us/step - loss: 0.3889 - accuracy: 0.8255\n",
      "Epoch 54/150\n",
      "808/808 [==============================] - 0s 53us/step - loss: 0.3954 - accuracy: 0.8193\n",
      "Epoch 55/150\n",
      "808/808 [==============================] - 0s 45us/step - loss: 0.3879 - accuracy: 0.8172\n",
      "Epoch 56/150\n",
      "808/808 [==============================] - 0s 44us/step - loss: 0.3845 - accuracy: 0.8300\n",
      "Epoch 57/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3827 - accuracy: 0.8284\n",
      "Epoch 58/150\n",
      "808/808 [==============================] - 0s 49us/step - loss: 0.3930 - accuracy: 0.8168\n",
      "Epoch 59/150\n",
      "808/808 [==============================] - 0s 50us/step - loss: 0.3821 - accuracy: 0.8255\n",
      "Epoch 60/150\n",
      "808/808 [==============================] - 0s 56us/step - loss: 0.3910 - accuracy: 0.8164\n",
      "Epoch 61/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.4021 - accuracy: 0.8119\n",
      "Epoch 62/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3862 - accuracy: 0.8115\n",
      "Epoch 63/150\n",
      "808/808 [==============================] - 0s 52us/step - loss: 0.3801 - accuracy: 0.8247\n",
      "Epoch 64/150\n",
      "808/808 [==============================] - 0s 47us/step - loss: 0.3917 - accuracy: 0.8197\n",
      "Epoch 65/150\n",
      "808/808 [==============================] - 0s 61us/step - loss: 0.3812 - accuracy: 0.8210\n",
      "Epoch 66/150\n",
      "808/808 [==============================] - 0s 59us/step - loss: 0.3848 - accuracy: 0.8259\n",
      "Epoch 67/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3743 - accuracy: 0.8408\n",
      "Epoch 68/150\n",
      "808/808 [==============================] - 0s 60us/step - loss: 0.3812 - accuracy: 0.8263\n",
      "Epoch 69/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3755 - accuracy: 0.8358\n",
      "Epoch 70/150\n",
      "808/808 [==============================] - 0s 54us/step - loss: 0.3765 - accuracy: 0.8317\n",
      "Epoch 71/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3938 - accuracy: 0.8020\n",
      "Epoch 72/150\n",
      "808/808 [==============================] - 0s 86us/step - loss: 0.3858 - accuracy: 0.8205\n",
      "Epoch 73/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3765 - accuracy: 0.8230\n",
      "Epoch 74/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.4039 - accuracy: 0.8053\n",
      "Epoch 75/150\n",
      "808/808 [==============================] - 0s 88us/step - loss: 0.3755 - accuracy: 0.8309\n",
      "Epoch 76/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3678 - accuracy: 0.8399\n",
      "Epoch 77/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3823 - accuracy: 0.8263\n",
      "Epoch 78/150\n",
      "808/808 [==============================] - 0s 57us/step - loss: 0.3672 - accuracy: 0.8346\n",
      "Epoch 79/150\n",
      "808/808 [==============================] - 0s 83us/step - loss: 0.3741 - accuracy: 0.8201\n",
      "Epoch 80/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3615 - accuracy: 0.8445\n",
      "Epoch 81/150\n",
      "808/808 [==============================] - 0s 60us/step - loss: 0.3733 - accuracy: 0.8280\n",
      "Epoch 82/150\n",
      "808/808 [==============================] - 0s 69us/step - loss: 0.3729 - accuracy: 0.8309\n",
      "Epoch 83/150\n",
      "808/808 [==============================] - 0s 75us/step - loss: 0.3580 - accuracy: 0.8424\n",
      "Epoch 84/150\n",
      "808/808 [==============================] - 0s 49us/step - loss: 0.3575 - accuracy: 0.8449\n",
      "Epoch 85/150\n",
      "808/808 [==============================] - 0s 48us/step - loss: 0.3667 - accuracy: 0.8342\n",
      "Epoch 86/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3769 - accuracy: 0.8255\n",
      "Epoch 87/150\n",
      "808/808 [==============================] - 0s 42us/step - loss: 0.3668 - accuracy: 0.8292\n",
      "Epoch 88/150\n",
      "808/808 [==============================] - 0s 60us/step - loss: 0.3545 - accuracy: 0.8482\n",
      "Epoch 89/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3594 - accuracy: 0.8346\n",
      "Epoch 90/150\n",
      "808/808 [==============================] - 0s 53us/step - loss: 0.3636 - accuracy: 0.8354\n",
      "Epoch 91/150\n",
      "808/808 [==============================] - 0s 49us/step - loss: 0.3747 - accuracy: 0.8346\n",
      "Epoch 92/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3668 - accuracy: 0.8296\n",
      "Epoch 93/150\n",
      "808/808 [==============================] - 0s 73us/step - loss: 0.3609 - accuracy: 0.8358\n",
      "Epoch 94/150\n",
      "808/808 [==============================] - 0s 73us/step - loss: 0.3567 - accuracy: 0.8432\n",
      "Epoch 95/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3569 - accuracy: 0.8408\n",
      "Epoch 96/150\n",
      "808/808 [==============================] - 0s 51us/step - loss: 0.3934 - accuracy: 0.8094\n",
      "Epoch 97/150\n",
      "808/808 [==============================] - 0s 47us/step - loss: 0.3663 - accuracy: 0.8276\n",
      "Epoch 98/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3534 - accuracy: 0.8478\n",
      "Epoch 99/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3509 - accuracy: 0.8428\n",
      "Epoch 100/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3540 - accuracy: 0.8441\n",
      "Epoch 101/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.3588 - accuracy: 0.8342\n",
      "Epoch 102/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3655 - accuracy: 0.8329\n",
      "Epoch 103/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.3507 - accuracy: 0.8465\n",
      "Epoch 104/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.3662 - accuracy: 0.8271\n",
      "Epoch 105/150\n",
      "808/808 [==============================] - 0s 78us/step - loss: 0.3620 - accuracy: 0.8288\n",
      "Epoch 106/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.3611 - accuracy: 0.8420\n",
      "Epoch 107/150\n",
      "808/808 [==============================] - 0s 84us/step - loss: 0.3567 - accuracy: 0.8309\n",
      "Epoch 108/150\n",
      "808/808 [==============================] - 0s 93us/step - loss: 0.3505 - accuracy: 0.8494\n",
      "Epoch 109/150\n",
      "808/808 [==============================] - 0s 90us/step - loss: 0.3504 - accuracy: 0.8478\n",
      "Epoch 110/150\n",
      "808/808 [==============================] - 0s 104us/step - loss: 0.3509 - accuracy: 0.8436\n",
      "Epoch 111/150\n",
      "808/808 [==============================] - 0s 115us/step - loss: 0.3598 - accuracy: 0.8234\n",
      "Epoch 112/150\n",
      "808/808 [==============================] - 0s 119us/step - loss: 0.3572 - accuracy: 0.8362\n",
      "Epoch 113/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3560 - accuracy: 0.8354\n",
      "Epoch 114/150\n",
      "808/808 [==============================] - 0s 79us/step - loss: 0.4002 - accuracy: 0.7950\n",
      "Epoch 115/150\n",
      "808/808 [==============================] - 0s 96us/step - loss: 0.3493 - accuracy: 0.8436\n",
      "Epoch 116/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.3638 - accuracy: 0.8267\n",
      "Epoch 117/150\n",
      "808/808 [==============================] - 0s 81us/step - loss: 0.3462 - accuracy: 0.8515\n",
      "Epoch 118/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3387 - accuracy: 0.8515\n",
      "Epoch 119/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3809 - accuracy: 0.8123\n",
      "Epoch 120/150\n",
      "808/808 [==============================] - 0s 67us/step - loss: 0.3558 - accuracy: 0.8329\n",
      "Epoch 121/150\n",
      "808/808 [==============================] - 0s 60us/step - loss: 0.3426 - accuracy: 0.8494\n",
      "Epoch 122/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3417 - accuracy: 0.8498\n",
      "Epoch 123/150\n",
      "808/808 [==============================] - 0s 48us/step - loss: 0.3531 - accuracy: 0.8358\n",
      "Epoch 124/150\n",
      "808/808 [==============================] - 0s 47us/step - loss: 0.3411 - accuracy: 0.8544\n",
      "Epoch 125/150\n",
      "808/808 [==============================] - 0s 57us/step - loss: 0.3529 - accuracy: 0.8300\n",
      "Epoch 126/150\n",
      "808/808 [==============================] - 0s 65us/step - loss: 0.3508 - accuracy: 0.8457\n",
      "Epoch 127/150\n",
      "808/808 [==============================] - 0s 50us/step - loss: 0.3409 - accuracy: 0.8540\n",
      "Epoch 128/150\n",
      "808/808 [==============================] - 0s 60us/step - loss: 0.3403 - accuracy: 0.8527\n",
      "Epoch 129/150\n",
      "808/808 [==============================] - 0s 68us/step - loss: 0.3365 - accuracy: 0.8482\n",
      "Epoch 130/150\n",
      "808/808 [==============================] - 0s 77us/step - loss: 0.3398 - accuracy: 0.8531\n",
      "Epoch 131/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.3509 - accuracy: 0.8408\n",
      "Epoch 132/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3763 - accuracy: 0.8255\n",
      "Epoch 133/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3442 - accuracy: 0.8391\n",
      "Epoch 134/150\n",
      "808/808 [==============================] - 0s 50us/step - loss: 0.3686 - accuracy: 0.8251\n",
      "Epoch 135/150\n",
      "808/808 [==============================] - 0s 53us/step - loss: 0.3511 - accuracy: 0.8432\n",
      "Epoch 136/150\n",
      "808/808 [==============================] - 0s 47us/step - loss: 0.3420 - accuracy: 0.8457\n",
      "Epoch 137/150\n",
      "808/808 [==============================] - 0s 56us/step - loss: 0.3641 - accuracy: 0.8205\n",
      "Epoch 138/150\n",
      "808/808 [==============================] - 0s 72us/step - loss: 0.3382 - accuracy: 0.8527\n",
      "Epoch 139/150\n",
      "808/808 [==============================] - 0s 52us/step - loss: 0.3375 - accuracy: 0.8531\n",
      "Epoch 140/150\n",
      "808/808 [==============================] - 0s 56us/step - loss: 0.3324 - accuracy: 0.8441\n",
      "Epoch 141/150\n",
      "808/808 [==============================] - 0s 56us/step - loss: 0.3661 - accuracy: 0.8243\n",
      "Epoch 142/150\n",
      "808/808 [==============================] - 0s 80us/step - loss: 0.3451 - accuracy: 0.8412\n",
      "Epoch 143/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.3362 - accuracy: 0.8502\n",
      "Epoch 144/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.3357 - accuracy: 0.8490\n",
      "Epoch 145/150\n",
      "808/808 [==============================] - 0s 58us/step - loss: 0.3348 - accuracy: 0.8544\n",
      "Epoch 146/150\n",
      "808/808 [==============================] - 0s 63us/step - loss: 0.3427 - accuracy: 0.8416\n",
      "Epoch 147/150\n",
      "808/808 [==============================] - 0s 55us/step - loss: 0.3407 - accuracy: 0.8519\n",
      "Epoch 148/150\n",
      "808/808 [==============================] - 0s 59us/step - loss: 0.3415 - accuracy: 0.8387\n",
      "Epoch 149/150\n",
      "808/808 [==============================] - 0s 62us/step - loss: 0.3396 - accuracy: 0.8412\n",
      "Epoch 150/150\n",
      "808/808 [==============================] - 0s 64us/step - loss: 0.3542 - accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1566b3c5f98>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "\n",
    "model.fit(y_train, X_train_categorical, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 0s 51us/step\n",
      "Accuracy on training data: 0.824257493019104% \n",
      " Error on training data: 0.175742506980896\n"
     ]
    }
   ],
   "source": [
    "#evaluate train data\n",
    "\n",
    "scores = model.evaluate(y_train, X_train_categorical)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 1, 0, 0, 1, 2, 0, 1, 1, 2, 1, 1, 2, 0, 1, 2, 0, 1, 1,\n",
       "       2, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 0, 1, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 0, 2, 0, 1, 1,\n",
       "       0, 1, 2, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 2, 1, 2, 1, 2, 2, 0, 1, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 2, 0, 2, 1, 0, 2, 2, 2, 1, 1, 2, 0, 2, 0, 0, 2, 0, 1,\n",
       "       1, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 1, 2, 0, 2, 2, 1, 1,\n",
       "       0, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTesting = y_test\n",
    "predictions = model.predict_classes(dataTesting)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluation confussion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matrix = confusion_matrix(X_test, predictions)\n",
    "sn.heatmap(matrix, annot=True)\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"True\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Error Rate: 0.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuration score from confussion matrix using library\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(X_test, predictions)))\n",
    "print('Error Rate: {:.2f}\\n'.format(1 - accuracy_score(X_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7673267326732673\n",
      "Error Rate: 0.23267326732673266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuration score from confussion matrix using mathematics\n",
    "\n",
    "accuration = (matrix[0,0]+matrix[1,1]+matrix[2,2])/len(predictions)\n",
    "print('Accuracy: {}'.format(accuration))\n",
    "print('Error Rate: {}\\n'.format(1 - accuration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
