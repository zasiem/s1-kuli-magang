{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['awal', 'scene', 'bawang', 'nang', 'keinget',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['gila', 'drama', 'cakep', 'cinematography', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>['jahat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['males', 'nonton', 'drakor', 'stalk', 'gtgt',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['nam', 'do', 'san', 'emang', 'kasih', 'previe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0  ['awal', 'scene', 'bawang', 'nang', 'keinget',...\n",
       "1      1  ['gila', 'drama', 'cakep', 'cinematography', '...\n",
       "2      0                                          ['jahat']\n",
       "3      0  ['males', 'nonton', 'drakor', 'stalk', 'gtgt',...\n",
       "4      0  ['nam', 'do', 'san', 'emang', 'kasih', 'previe..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "tweets = pd.read_excel('tweets-stemmed.xlsx', usecols=['label','tweet_token_stemmed'])\n",
    "tweets.columns = ['label','tweet']\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awal scene bawang nang keinget karakter romant...\n",
       "1    gila drama cakep cinematography kece cerita ba...\n",
       "2                                                jahat\n",
       "3                 males nonton drakor stalk gtgt wkwkw\n",
       "4    nam do san emang kasih preview dikit opening d...\n",
       "Name: tweet_join, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse string to list\n",
    "import ast\n",
    "\n",
    "#join list\n",
    "def join_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return ' '.join([text for text in texts])\n",
    "tweets[\"tweet_join\"] = tweets[\"tweet\"].apply(join_text_list)\n",
    "tweets[\"tweet_join\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_join\n",
      "0  awal scene bawang nang keinget karakter romant...\n",
      "1  gila drama cakep cinematography kece cerita ba...\n",
      "2                                              jahat\n",
      "3               males nonton drakor stalk gtgt wkwkw\n",
      "4  nam do san emang kasih preview dikit opening d...\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#define predictor and target for classification\n",
    "\n",
    "target = 'label'\n",
    "predictor = ['tweet_join']\n",
    "y = tweets[target]\n",
    "X = tweets[predictor]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1668, 1)\n",
      "(1668,)\n",
      "(417, 1)\n",
      "(417,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=200)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1668, 3)\n",
      "<class 'numpy.ndarray'> (417, 3)\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "print(type(y_train_categorical),y_train_categorical.shape)\n",
    "print(type(y_test_categorical),y_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1668, 1500)\n",
      "<class 'numpy.ndarray'> (417, 1500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "max_features = 1500\n",
    "\n",
    "tf_idf = TfidfVectorizer(max_features=max_features)\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train['tweet_join']).toarray()\n",
    "X_test_tfidf = tf_idf.fit_transform(X_test['tweet_join']).toarray()\n",
    "\n",
    "print(type(X_train_tfidf), X_train_tfidf.shape)\n",
    "print(type(X_test_tfidf), X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1668/1668 [==============================] - 0s 187us/step - loss: 1.0794 - accuracy: 0.4946\n",
      "Epoch 2/150\n",
      "1668/1668 [==============================] - 0s 74us/step - loss: 1.0037 - accuracy: 0.5234\n",
      "Epoch 3/150\n",
      "1668/1668 [==============================] - 0s 62us/step - loss: 0.8663 - accuracy: 0.6163\n",
      "Epoch 4/150\n",
      "1668/1668 [==============================] - 0s 66us/step - loss: 0.6790 - accuracy: 0.7428\n",
      "Epoch 5/150\n",
      "1668/1668 [==============================] - 0s 66us/step - loss: 0.5218 - accuracy: 0.7986\n",
      "Epoch 6/150\n",
      "1668/1668 [==============================] - 0s 63us/step - loss: 0.3773 - accuracy: 0.8717\n",
      "Epoch 7/150\n",
      "1668/1668 [==============================] - 0s 64us/step - loss: 0.2628 - accuracy: 0.9263\n",
      "Epoch 8/150\n",
      "1668/1668 [==============================] - 0s 63us/step - loss: 0.1903 - accuracy: 0.9532\n",
      "Epoch 9/150\n",
      "1668/1668 [==============================] - 0s 81us/step - loss: 0.1440 - accuracy: 0.9616\n",
      "Epoch 10/150\n",
      "1668/1668 [==============================] - 0s 91us/step - loss: 0.1179 - accuracy: 0.9652\n",
      "Epoch 11/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0985 - accuracy: 0.9736\n",
      "Epoch 12/150\n",
      "1668/1668 [==============================] - 0s 61us/step - loss: 0.0834 - accuracy: 0.9760\n",
      "Epoch 13/150\n",
      "1668/1668 [==============================] - 0s 60us/step - loss: 0.0772 - accuracy: 0.9778\n",
      "Epoch 14/150\n",
      "1668/1668 [==============================] - 0s 57us/step - loss: 0.0738 - accuracy: 0.9754\n",
      "Epoch 15/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0672 - accuracy: 0.9772\n",
      "Epoch 16/150\n",
      "1668/1668 [==============================] - 0s 80us/step - loss: 0.0669 - accuracy: 0.9766\n",
      "Epoch 17/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0619 - accuracy: 0.9790\n",
      "Epoch 18/150\n",
      "1668/1668 [==============================] - 0s 78us/step - loss: 0.0620 - accuracy: 0.9778\n",
      "Epoch 19/150\n",
      "1668/1668 [==============================] - 0s 77us/step - loss: 0.0567 - accuracy: 0.9820\n",
      "Epoch 20/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0566 - accuracy: 0.9772\n",
      "Epoch 21/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0525 - accuracy: 0.9802\n",
      "Epoch 22/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0536 - accuracy: 0.9808\n",
      "Epoch 23/150\n",
      "1668/1668 [==============================] - 0s 63us/step - loss: 0.0529 - accuracy: 0.9784\n",
      "Epoch 24/150\n",
      "1668/1668 [==============================] - 0s 68us/step - loss: 0.0476 - accuracy: 0.9814\n",
      "Epoch 25/150\n",
      "1668/1668 [==============================] - 0s 67us/step - loss: 0.0478 - accuracy: 0.9802\n",
      "Epoch 26/150\n",
      "1668/1668 [==============================] - 0s 62us/step - loss: 0.0525 - accuracy: 0.9802\n",
      "Epoch 27/150\n",
      "1668/1668 [==============================] - 0s 62us/step - loss: 0.0472 - accuracy: 0.9814\n",
      "Epoch 28/150\n",
      "1668/1668 [==============================] - 0s 60us/step - loss: 0.0458 - accuracy: 0.9802\n",
      "Epoch 29/150\n",
      "1668/1668 [==============================] - 0s 62us/step - loss: 0.0468 - accuracy: 0.9796\n",
      "Epoch 30/150\n",
      "1668/1668 [==============================] - 0s 60us/step - loss: 0.0447 - accuracy: 0.9820\n",
      "Epoch 31/150\n",
      "1668/1668 [==============================] - 0s 61us/step - loss: 0.0484 - accuracy: 0.9790\n",
      "Epoch 32/150\n",
      "1668/1668 [==============================] - 0s 59us/step - loss: 0.0444 - accuracy: 0.9820\n",
      "Epoch 33/150\n",
      "1668/1668 [==============================] - 0s 59us/step - loss: 0.0461 - accuracy: 0.9808\n",
      "Epoch 34/150\n",
      "1668/1668 [==============================] - 0s 60us/step - loss: 0.0470 - accuracy: 0.9826\n",
      "Epoch 35/150\n",
      "1668/1668 [==============================] - 0s 60us/step - loss: 0.0456 - accuracy: 0.9790\n",
      "Epoch 36/150\n",
      "1668/1668 [==============================] - 0s 59us/step - loss: 0.0484 - accuracy: 0.9814\n",
      "Epoch 37/150\n",
      "1668/1668 [==============================] - 0s 83us/step - loss: 0.0467 - accuracy: 0.9796\n",
      "Epoch 38/150\n",
      "1668/1668 [==============================] - 0s 82us/step - loss: 0.0464 - accuracy: 0.9802\n",
      "Epoch 39/150\n",
      "1668/1668 [==============================] - 0s 83us/step - loss: 0.0494 - accuracy: 0.9832\n",
      "Epoch 40/150\n",
      "1668/1668 [==============================] - 0s 81us/step - loss: 0.0450 - accuracy: 0.9808\n",
      "Epoch 41/150\n",
      "1668/1668 [==============================] - 0s 71us/step - loss: 0.0461 - accuracy: 0.9820\n",
      "Epoch 42/150\n",
      "1668/1668 [==============================] - 0s 63us/step - loss: 0.0430 - accuracy: 0.9802\n",
      "Epoch 43/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0447 - accuracy: 0.9802\n",
      "Epoch 44/150\n",
      "1668/1668 [==============================] - 0s 88us/step - loss: 0.0412 - accuracy: 0.9784\n",
      "Epoch 45/150\n",
      "1668/1668 [==============================] - 0s 94us/step - loss: 0.0423 - accuracy: 0.9820\n",
      "Epoch 46/150\n",
      "1668/1668 [==============================] - 0s 91us/step - loss: 0.0427 - accuracy: 0.9766\n",
      "Epoch 47/150\n",
      "1668/1668 [==============================] - 0s 77us/step - loss: 0.0422 - accuracy: 0.9814\n",
      "Epoch 48/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0421 - accuracy: 0.9796\n",
      "Epoch 49/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0391 - accuracy: 0.9778\n",
      "Epoch 50/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0404 - accuracy: 0.9814\n",
      "Epoch 51/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0381 - accuracy: 0.9820\n",
      "Epoch 52/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0392 - accuracy: 0.9796\n",
      "Epoch 53/150\n",
      "1668/1668 [==============================] - 0s 88us/step - loss: 0.0398 - accuracy: 0.9814\n",
      "Epoch 54/150\n",
      "1668/1668 [==============================] - 0s 92us/step - loss: 0.0425 - accuracy: 0.9796\n",
      "Epoch 55/150\n",
      "1668/1668 [==============================] - 0s 83us/step - loss: 0.0406 - accuracy: 0.9796\n",
      "Epoch 56/150\n",
      "1668/1668 [==============================] - 0s 66us/step - loss: 0.0396 - accuracy: 0.9808\n",
      "Epoch 57/150\n",
      "1668/1668 [==============================] - 0s 66us/step - loss: 0.0381 - accuracy: 0.9808\n",
      "Epoch 58/150\n",
      "1668/1668 [==============================] - 0s 68us/step - loss: 0.0400 - accuracy: 0.9772\n",
      "Epoch 59/150\n",
      "1668/1668 [==============================] - 0s 61us/step - loss: 0.0381 - accuracy: 0.9796\n",
      "Epoch 60/150\n",
      "1668/1668 [==============================] - 0s 63us/step - loss: 0.0369 - accuracy: 0.9796\n",
      "Epoch 61/150\n",
      "1668/1668 [==============================] - 0s 64us/step - loss: 0.0371 - accuracy: 0.9814\n",
      "Epoch 62/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0429 - accuracy: 0.9802\n",
      "Epoch 63/150\n",
      "1668/1668 [==============================] - 0s 76us/step - loss: 0.0390 - accuracy: 0.9826\n",
      "Epoch 64/150\n",
      "1668/1668 [==============================] - 0s 66us/step - loss: 0.0382 - accuracy: 0.9820\n",
      "Epoch 65/150\n",
      "1668/1668 [==============================] - 0s 62us/step - loss: 0.0381 - accuracy: 0.9784\n",
      "Epoch 66/150\n",
      "1668/1668 [==============================] - 0s 60us/step - loss: 0.0388 - accuracy: 0.9808\n",
      "Epoch 67/150\n",
      "1668/1668 [==============================] - 0s 63us/step - loss: 0.0380 - accuracy: 0.9808\n",
      "Epoch 68/150\n",
      "1668/1668 [==============================] - 0s 68us/step - loss: 0.0380 - accuracy: 0.9802\n",
      "Epoch 69/150\n",
      "1668/1668 [==============================] - 0s 86us/step - loss: 0.0380 - accuracy: 0.9802\n",
      "Epoch 70/150\n",
      "1668/1668 [==============================] - 0s 87us/step - loss: 0.0384 - accuracy: 0.9784\n",
      "Epoch 71/150\n",
      "1668/1668 [==============================] - 0s 84us/step - loss: 0.0380 - accuracy: 0.9784\n",
      "Epoch 72/150\n",
      "1668/1668 [==============================] - 0s 74us/step - loss: 0.0378 - accuracy: 0.9814\n",
      "Epoch 73/150\n",
      "1668/1668 [==============================] - 0s 125us/step - loss: 0.0433 - accuracy: 0.9826\n",
      "Epoch 74/150\n",
      "1668/1668 [==============================] - 1s 523us/step - loss: 0.0396 - accuracy: 0.9820\n",
      "Epoch 75/150\n",
      "1668/1668 [==============================] - 1s 718us/step - loss: 0.0430 - accuracy: 0.98200s - loss: 0\n",
      "Epoch 76/150\n",
      "1668/1668 [==============================] - 1s 588us/step - loss: 0.0395 - accuracy: 0.9814TA: 1s - loss: 0.0055 - ac - ETA: 0s - loss: 0.0315 - accuracy: 0. - ETA: 0s - loss: 0.0297 - accuracy: 0.98 - ETA: 0s - loss: 0.0338 - accuracy\n",
      "Epoch 77/150\n",
      "1668/1668 [==============================] - 0s 139us/step - loss: 0.0397 - accuracy: 0.97900s - loss: 0.0481 - accuracy\n",
      "Epoch 78/150\n",
      "1668/1668 [==============================] - 0s 116us/step - loss: 0.0378 - accuracy: 0.9790\n",
      "Epoch 79/150\n",
      "1668/1668 [==============================] - 0s 91us/step - loss: 0.0373 - accuracy: 0.9814\n",
      "Epoch 80/150\n",
      "1668/1668 [==============================] - 0s 103us/step - loss: 0.0387 - accuracy: 0.9790\n",
      "Epoch 81/150\n",
      "1668/1668 [==============================] - 0s 119us/step - loss: 0.0358 - accuracy: 0.9808\n",
      "Epoch 82/150\n",
      "1668/1668 [==============================] - 0s 94us/step - loss: 0.0371 - accuracy: 0.9808\n",
      "Epoch 83/150\n",
      "1668/1668 [==============================] - 0s 74us/step - loss: 0.0366 - accuracy: 0.9796\n",
      "Epoch 84/150\n",
      "1668/1668 [==============================] - 0s 66us/step - loss: 0.0379 - accuracy: 0.9778 0s - loss: 0.0380 - accuracy: 0.97\n",
      "Epoch 85/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0364 - accuracy: 0.9796\n",
      "Epoch 86/150\n",
      "1668/1668 [==============================] - 0s 79us/step - loss: 0.0385 - accuracy: 0.9802\n",
      "Epoch 87/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0381 - accuracy: 0.9784\n",
      "Epoch 88/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0368 - accuracy: 0.9808\n",
      "Epoch 89/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0372 - accuracy: 0.9790\n",
      "Epoch 90/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0359 - accuracy: 0.9796\n",
      "Epoch 91/150\n",
      "1668/1668 [==============================] - 0s 71us/step - loss: 0.0384 - accuracy: 0.9790\n",
      "Epoch 92/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0375 - accuracy: 0.9820\n",
      "Epoch 93/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0372 - accuracy: 0.9808\n",
      "Epoch 94/150\n",
      "1668/1668 [==============================] - 0s 71us/step - loss: 0.0386 - accuracy: 0.9826\n",
      "Epoch 95/150\n",
      "1668/1668 [==============================] - 0s 77us/step - loss: 0.0368 - accuracy: 0.9820\n",
      "Epoch 96/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0371 - accuracy: 0.9808\n",
      "Epoch 97/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0375 - accuracy: 0.9778\n",
      "Epoch 98/150\n",
      "1668/1668 [==============================] - 0s 71us/step - loss: 0.0374 - accuracy: 0.9802\n",
      "Epoch 99/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0374 - accuracy: 0.9808\n",
      "Epoch 100/150\n",
      "1668/1668 [==============================] - 0s 66us/step - loss: 0.0358 - accuracy: 0.9802\n",
      "Epoch 101/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0365 - accuracy: 0.9814\n",
      "Epoch 102/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0392 - accuracy: 0.9820\n",
      "Epoch 103/150\n",
      "1668/1668 [==============================] - 0s 68us/step - loss: 0.0359 - accuracy: 0.9814\n",
      "Epoch 104/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0364 - accuracy: 0.9814\n",
      "Epoch 105/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0361 - accuracy: 0.9808\n",
      "Epoch 106/150\n",
      "1668/1668 [==============================] - 0s 76us/step - loss: 0.0367 - accuracy: 0.9796\n",
      "Epoch 107/150\n",
      "1668/1668 [==============================] - 0s 71us/step - loss: 0.0360 - accuracy: 0.9802\n",
      "Epoch 108/150\n",
      "1668/1668 [==============================] - 0s 77us/step - loss: 0.0375 - accuracy: 0.9826\n",
      "Epoch 109/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0385 - accuracy: 0.9790\n",
      "Epoch 110/150\n",
      "1668/1668 [==============================] - 0s 73us/step - loss: 0.0364 - accuracy: 0.9784\n",
      "Epoch 111/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0351 - accuracy: 0.9790\n",
      "Epoch 112/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0350 - accuracy: 0.9802\n",
      "Epoch 113/150\n",
      "1668/1668 [==============================] - 0s 81us/step - loss: 0.0352 - accuracy: 0.9826\n",
      "Epoch 114/150\n",
      "1668/1668 [==============================] - 0s 79us/step - loss: 0.0351 - accuracy: 0.9820\n",
      "Epoch 115/150\n",
      "1668/1668 [==============================] - 0s 74us/step - loss: 0.0358 - accuracy: 0.9814\n",
      "Epoch 116/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0351 - accuracy: 0.9808\n",
      "Epoch 117/150\n",
      "1668/1668 [==============================] - 0s 100us/step - loss: 0.0353 - accuracy: 0.9802\n",
      "Epoch 118/150\n",
      "1668/1668 [==============================] - 0s 97us/step - loss: 0.0369 - accuracy: 0.9784\n",
      "Epoch 119/150\n",
      "1668/1668 [==============================] - 0s 91us/step - loss: 0.0356 - accuracy: 0.9808\n",
      "Epoch 120/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0353 - accuracy: 0.9826\n",
      "Epoch 121/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0362 - accuracy: 0.9784\n",
      "Epoch 122/150\n",
      "1668/1668 [==============================] - 0s 91us/step - loss: 0.0357 - accuracy: 0.9802\n",
      "Epoch 123/150\n",
      "1668/1668 [==============================] - 0s 91us/step - loss: 0.0386 - accuracy: 0.9826\n",
      "Epoch 124/150\n",
      "1668/1668 [==============================] - 0s 70us/step - loss: 0.0369 - accuracy: 0.9826\n",
      "Epoch 125/150\n",
      "1668/1668 [==============================] - 0s 68us/step - loss: 0.0369 - accuracy: 0.9784\n",
      "Epoch 126/150\n",
      "1668/1668 [==============================] - 0s 71us/step - loss: 0.0367 - accuracy: 0.9796\n",
      "Epoch 127/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0361 - accuracy: 0.9802\n",
      "Epoch 128/150\n",
      "1668/1668 [==============================] - 0s 70us/step - loss: 0.0344 - accuracy: 0.9802\n",
      "Epoch 129/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0350 - accuracy: 0.9808\n",
      "Epoch 130/150\n",
      "1668/1668 [==============================] - 0s 70us/step - loss: 0.0350 - accuracy: 0.9802\n",
      "Epoch 131/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0352 - accuracy: 0.9790\n",
      "Epoch 132/150\n",
      "1668/1668 [==============================] - 0s 70us/step - loss: 0.0344 - accuracy: 0.9790\n",
      "Epoch 133/150\n",
      "1668/1668 [==============================] - 0s 71us/step - loss: 0.0344 - accuracy: 0.9820\n",
      "Epoch 134/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0357 - accuracy: 0.9784\n",
      "Epoch 135/150\n",
      "1668/1668 [==============================] - 0s 70us/step - loss: 0.0394 - accuracy: 0.9808\n",
      "Epoch 136/150\n",
      "1668/1668 [==============================] - 0s 65us/step - loss: 0.0357 - accuracy: 0.9802\n",
      "Epoch 137/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0364 - accuracy: 0.9808\n",
      "Epoch 138/150\n",
      "1668/1668 [==============================] - 0s 67us/step - loss: 0.0354 - accuracy: 0.9820\n",
      "Epoch 139/150\n",
      "1668/1668 [==============================] - 0s 65us/step - loss: 0.0354 - accuracy: 0.9784\n",
      "Epoch 140/150\n",
      "1668/1668 [==============================] - 0s 65us/step - loss: 0.0352 - accuracy: 0.9784\n",
      "Epoch 141/150\n",
      "1668/1668 [==============================] - 0s 77us/step - loss: 0.0344 - accuracy: 0.9790\n",
      "Epoch 142/150\n",
      "1668/1668 [==============================] - 0s 77us/step - loss: 0.0345 - accuracy: 0.9802\n",
      "Epoch 143/150\n",
      "1668/1668 [==============================] - 0s 72us/step - loss: 0.0340 - accuracy: 0.9784\n",
      "Epoch 144/150\n",
      "1668/1668 [==============================] - 0s 69us/step - loss: 0.0344 - accuracy: 0.9796\n",
      "Epoch 145/150\n",
      "1668/1668 [==============================] - 0s 75us/step - loss: 0.0357 - accuracy: 0.9778\n",
      "Epoch 146/150\n",
      "1668/1668 [==============================] - 0s 78us/step - loss: 0.0346 - accuracy: 0.9796\n",
      "Epoch 147/150\n",
      "1668/1668 [==============================] - 0s 87us/step - loss: 0.0348 - accuracy: 0.9808\n",
      "Epoch 148/150\n",
      "1668/1668 [==============================] - 0s 85us/step - loss: 0.0351 - accuracy: 0.9808\n",
      "Epoch 149/150\n",
      "1668/1668 [==============================] - 0s 90us/step - loss: 0.0339 - accuracy: 0.9808\n",
      "Epoch 150/150\n",
      "1668/1668 [==============================] - 0s 74us/step - loss: 0.0350 - accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c085406d68>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating model sequential\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=1500, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#compile kelas model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_tfidf, y_train_categorical, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/1668 [==============================] - 0s 31us/step\n",
      "Accuracy on training data: 0.9844124913215637% \n",
      " Error on training data: 0.01558750867843628\n"
     ]
    }
   ],
   "source": [
    "#evaluate train data\n",
    "\n",
    "scores = model.evaluate(X_train_tfidf, y_train_categorical)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0,\n",
       "       1, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 0, 2, 1, 2, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1, 1,\n",
       "       0, 2, 2, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2,\n",
       "       0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 2, 2, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 2, 0, 0, 0, 1, 1, 0,\n",
       "       0, 2, 0, 1, 2, 2, 2, 1, 1, 0, 0, 2, 2, 1, 0, 1, 1, 2, 2, 1, 0, 2,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 0, 1, 0, 1,\n",
       "       0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 2, 2, 0, 1, 0, 1, 0, 2, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1, 0, 2, 0, 0, 2, 2, 0, 1, 1,\n",
       "       0, 1, 1, 2, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTesting = X_test_tfidf\n",
    "predictions = model.predict_classes(dataTesting)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluation confussion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matrix = confusion_matrix(y_test, predictions)\n",
    "sn.heatmap(matrix, annot=True)\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"True\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41\n",
      "Error Rate: 0.59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuration score from confussion matrix using library\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('Error Rate: {:.2f}\\n'.format(1 - accuracy_score(y_test, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
